{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "olaCwrdf1I4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt_llm -U --pre --extra-index-url https://pypi.nvidia.com\n",
        "!pip install transformers -U"
      ],
      "metadata": {
        "id": "kSL5Bq1PIcnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-dW6pT4usga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28345b6a-bfc9-43c0-ab98-b57d7955541f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import re\n",
        "import torch\n",
        "\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from datasets import load_dataset, Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, TextIteratorStreamer, AutoTokenizer\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             classification_report, confusion_matrix)\n",
        "from tqdm.auto import tqdm\n",
        "from tensorrt_llm.runtime import ModelRunner"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Dataset**"
      ],
      "metadata": {
        "id": "1htN-GODAwvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"dair-ai/emotion\")"
      ],
      "metadata": {
        "id": "4w7T8oBo4jMy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[\"train\"].to_pandas()\n",
        "test_dataset = dataset[\"test\"].to_pandas()\n",
        "val_dataset = dataset[\"validation\"].to_pandas()"
      ],
      "metadata": {
        "id": "Te9gTYVt08n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Model**"
      ],
      "metadata": {
        "id": "j0juKgqcOO51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = base_model,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit\n",
        ")"
      ],
      "metadata": {
        "id": "BgLp-zq7OV0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformed Dataset**"
      ],
      "metadata": {
        "id": "n2OyBaYBIxJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_map = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "\n",
        "emotion_list = \"['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\""
      ],
      "metadata": {
        "id": "eU9NSd9rBzmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_question(text):\n",
        "    prompt = f\"\"\"\n",
        "    <task>\n",
        "    Perform a deep emotional reasoning analysis on the provided sentence.\n",
        "    </task>\n",
        "\n",
        "    <sentence>\n",
        "    {text}\n",
        "    </sentence>\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_cot(text, emotion):\n",
        "    templates = {\n",
        "        'sadness': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to loss, grief, disappointment, or hopelessness.\n",
        "    3. Assess tone: The tone is heavy, somber, or melancholic.\n",
        "    4. Reasoning: The speaker expresses a sense of unhappiness or emotional pain regarding a situation.\n",
        "    5. Conclusion: The primary emotion is sadness.\n",
        "    \"\"\",\n",
        "\n",
        "        'joy': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to happiness, success, excitement, or gratitude.\n",
        "    3. Assess tone: The tone is uplifting, enthusiastic, or positive.\n",
        "    4. Reasoning: The speaker conveys a state of well-being, pleasure, or satisfaction.\n",
        "    5. Conclusion: The primary emotion is joy.\n",
        "    \"\"\",\n",
        "\n",
        "        'love': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to affection, devotion, intimacy, or caring.\n",
        "    3. Assess tone: The tone is warm, tender, or passionate.\n",
        "    4. Reasoning: The speaker expresses deep attachment or strong positive feelings towards someone or something.\n",
        "    5. Conclusion: The primary emotion is love.\n",
        "    \"\"\",\n",
        "\n",
        "        'anger': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to frustration, irritation, hostility, or rage.\n",
        "    3. Assess tone: The tone is aggressive, harsh, or defensive.\n",
        "    4. Reasoning: The speaker shows strong displeasure or antagonism towards a trigger or person.\n",
        "    5. Conclusion: The primary emotion is anger.\n",
        "    \"\"\",\n",
        "\n",
        "        'fear': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to anxiety, danger, panic, or uncertainty.\n",
        "    3. Assess tone: The tone is nervous, tense, or urgent.\n",
        "    4. Reasoning: The speaker anticipates a threat or feels unsafe about a future or current event.\n",
        "    5. Conclusion: The primary emotion is fear.\n",
        "    \"\"\",\n",
        "\n",
        "        'surprise': f\"\"\"\n",
        "    1. Analyze input: \"{text}\"\n",
        "    2. Identify keywords: Look for terms related to shock, disbelief, suddenness, or unexpected events.\n",
        "    3. Assess tone: The tone is startled, amazed, or confused (neutral to positive/negative).\n",
        "    4. Reasoning: The speaker is reacting to something unforeseen or contrary to expectations.\n",
        "    5. Conclusion: The primary emotion is surprise.\n",
        "    \"\"\"\n",
        "    }\n",
        "\n",
        "    return templates.get(emotion, \"\")"
      ],
      "metadata": {
        "id": "3HDnScr39Z9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    transformed_data = pd.DataFrame(columns=['Question', 'Complex_CoT', 'Response'])\n",
        "\n",
        "    transformed_data[\"Response\"] = data[\"label\"].apply(lambda x: emotion_map[x])\n",
        "    transformed_data[\"Question\"] = data[\"text\"].apply(create_question)\n",
        "    transformed_data[\"Complex_CoT\"] = data.apply(\n",
        "        lambda row: generate_cot(row[\"text\"], emotion_map[row[\"label\"]]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "def mapping_response(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    data['label'] = data['label'].apply(lambda x: emotion_map[x])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "qbLYK0d_-IbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_train = transform_data_train(train_dataset).reset_index(drop=True)\n",
        "transformed_test = mapping_response(test_dataset)\n",
        "transformed_val = mapping_response(val_dataset)"
      ],
      "metadata": {
        "id": "GWF9TCmE_Rib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "kq-boCcTNzql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prepare Dataset for Training**"
      ],
      "metadata": {
        "id": "REgm4ukqXDrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_style = r\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and emotionally insightful response.\n",
        "\n",
        "### Instruction:\n",
        "You are an expert in emotional intelligence and sentiment analysis.\n",
        "Analyze the given sentence and identify the primary emotion expressed by the speaker.\n",
        "Follow the Cognitive Appraisal Theory framework to evaluate the speaker's goals and agency.\n",
        "Choose only ONE emotion from the provided list: sadness, joy, love, anger, fear, surprise.\n",
        "\n",
        "Please follow these steps:\n",
        "1. Analyze the keywords, tone, and context within <think> tags.\n",
        "2. Determine the most dominant emotion based on your analysis.\n",
        "3. Output the final emotion explicitly within <Emotions> tags.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "\n",
        "Final Answer:\n",
        "<Emotions>{}</Emotions>\"\"\""
      ],
      "metadata": {
        "id": "wee2hw8SOAxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "8syTr9PkVhcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    questions = examples[\"Question\"]\n",
        "    cots = examples[\"Complex_CoT\"]\n",
        "    responses = examples[\"Response\"]\n",
        "    texts = []\n",
        "\n",
        "    for question, cot, response in zip(questions, cots, responses):\n",
        "        text = train_prompt_style.format(question, cot, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "\n",
        "    return {\"text\": texts}\n",
        "\n",
        "train_dataset = Dataset.from_pandas(transformed_train)\n",
        "train_dataset_modeling = train_dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "print(\"\\nðŸ“„ Sample formatted text:\")\n",
        "print(train_dataset_modeling[\"text\"][0][:])"
      ],
      "metadata": {
        "id": "5E1BR0WQVrHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup LoRA PEFT**"
      ],
      "metadata": {
        "id": "DOENOWhBXBQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")"
      ],
      "metadata": {
        "id": "4l0dnKpKOQit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edb00fe-0341-4afb-9cbe-b294a3b09179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.2.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup Training Arguments**"
      ],
      "metadata": {
        "id": "QAA-wu4yXU6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset_modeling,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,  # Effective batch = 8\n",
        "        warmup_steps=10,\n",
        "        num_train_epochs=1,  # Atau pakai max_steps\n",
        "        max_steps=100,  # Alternatif: fixed steps\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "4-rLh_cmOcUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "VCTbbYR-Opi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Prediction**"
      ],
      "metadata": {
        "id": "JWcvwVWxOyE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_prompt_style = r\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and emotionally insightful response.\n",
        "\n",
        "### Instruction:\n",
        "You are an expert in emotional intelligence and sentiment analysis.\n",
        "Analyze the given sentence and identify the primary emotion expressed by the speaker.\n",
        "Follow the Cognitive Appraisal Theory framework to evaluate the speaker's goals and agency.\n",
        "Choose only ONE emotion from the provided list: sadness, joy, love, anger, fear, surprise.\n",
        "\n",
        "Please follow these steps:\n",
        "1. Analyze the keywords, tone, and context within <think> tags.\n",
        "2. Determine the most dominant emotion based on your analysis.\n",
        "3. Output the final emotion explicitly within <Emotions> tags.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mgqnfkTp7xaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_list = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
        "\n",
        "def extract_emotion(response_text, emotion_list):\n",
        "    try:\n",
        "        emotion_pattern = r'<Emotions>\\s*([^<]+?)\\s*</Emotions>'\n",
        "        emotion_match = re.search(emotion_pattern, response_text, re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "        if emotion_match:\n",
        "            emotion_content = emotion_match.group(1).strip()\n",
        "\n",
        "            emotion_content = emotion_content.strip('.,;:!? \\n\\r\\t').lower()\n",
        "\n",
        "            emotion_list_lower = [e.lower() for e in emotion_list]\n",
        "            if emotion_content in emotion_list_lower:\n",
        "                return emotion_content\n",
        "\n",
        "            words = emotion_content.split()\n",
        "            for word in words:\n",
        "                clean_word = word.strip('.,;:!?').lower()\n",
        "                if clean_word in emotion_list_lower:\n",
        "                    return clean_word\n",
        "\n",
        "        text_without_think = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "        pattern = r'\\b(' + '|'.join(emotion_list) + r')\\b'\n",
        "        matches = re.findall(pattern, text_without_think, re.IGNORECASE)\n",
        "        if matches:\n",
        "            return matches[-1].lower()\n",
        "\n",
        "        return \"unknown\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return \"unknown\""
      ],
      "metadata": {
        "id": "CVqa-iss-6k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = create_question(\"im feeling quite sad and sorry for myself but ill snap out of it soon\")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "input_text = inference_prompt_style.format(question)\n",
        "inputs = tokenizer([input_text], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True,\n",
        "    stop_strings=[\"<ï½œendâ–ofâ–sentenceï½œ>\", \"</s>\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)\n",
        "print(f\"Output dari extract emotion : {extract_emotion(generated_text, emotion_list)}\")"
      ],
      "metadata": {
        "id": "nXUAlKCN3tLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate Model**"
      ],
      "metadata": {
        "id": "QANYCnHRKh6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_batch(texts, model, tokenizer, prompt_style, emotion_list, batch_size=8):\n",
        "    predictions = []\n",
        "\n",
        "    tokenizer.padding_side = \"left\"\n",
        "\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "        try:\n",
        "            questions = [create_question(text) for text in batch_texts]\n",
        "\n",
        "            prompts = [inference_prompt_style.format(q) for q in questions]\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                prompts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=2048\n",
        "            ).to(\"cuda\")\n",
        "\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs.input_ids,\n",
        "                attention_mask=inputs.attention_mask,\n",
        "                max_new_tokens=1024,\n",
        "                use_cache=True,\n",
        "                stop_strings=[\"<ï½œendâ–ofâ–sentenceï½œ>\", \"</s>\"],\n",
        "                tokenizer=tokenizer\n",
        "            )\n",
        "\n",
        "            generated_ids = outputs[:, inputs.input_ids.shape[1]:]\n",
        "            responses = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            for response_text in responses:\n",
        "\n",
        "                emotion = extract_emotion(response_text, emotion_list)\n",
        "                predictions.append(emotion)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing batch {i//batch_size + 1}: {str(e)}\")\n",
        "            predictions.extend([\"unknown\"] * len(batch_texts))\n",
        "            continue\n",
        "\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    if len(predictions) != len(texts):\n",
        "        print(f\"Warning: Got {len(predictions)} predictions for {len(texts)} texts\")\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "inLyu7FF_F7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = transformed_val['text'].tolist()\n",
        "true_labels = transformed_val['label'].tolist()\n",
        "\n",
        "predictions = predict_batch(texts, model, tokenizer, inference_prompt_style, emotion_list, batch_size=32)\n",
        "\n",
        "transformed_val['predicted'] = predictions"
      ],
      "metadata": {
        "id": "IWAyo_ijKDTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(true_labels, predictions, emotion_list):\n",
        "    # Filter unknown predictions\n",
        "    valid_indices = [i for i, pred in enumerate(predictions) if pred != \"unknown\"]\n",
        "\n",
        "    if len(valid_indices) == 0:\n",
        "        print(\"No valid predictions\")\n",
        "        return None\n",
        "\n",
        "    filtered_true = [true_labels[i] for i in valid_indices]\n",
        "    filtered_pred = [predictions[i] for i in valid_indices]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "\n",
        "    # Precision, Recall, F1\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        filtered_true, filtered_pred, labels=emotion_list, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Macro averages\n",
        "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
        "        filtered_true, filtered_pred, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(filtered_true, filtered_pred, labels=emotion_list)\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'support': support,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'macro_f1': macro_f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'valid_count': len(valid_indices),\n",
        "        'total_count': len(predictions),\n",
        "        'unknown_count': len(predictions) - len(valid_indices)\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "w2PjOIEMKTJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = calculate_metrics(true_labels, predictions, emotion_list)\n",
        "\n",
        "if results:\n",
        "    print(\"=\"*60)\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nTotal samples: {results['total_count']}\")\n",
        "    print(f\"Valid predictions: {results['valid_count']}\")\n",
        "    print(f\"Unknown predictions: {results['unknown_count']}\")\n",
        "    print(f\"\\nOverall Accuracy: {results['accuracy']:.4f}\")\n",
        "    print(f\"\\nMacro Precision: {results['macro_precision']:.4f}\")\n",
        "    print(f\"Macro Recall: {results['macro_recall']:.4f}\")\n",
        "    print(f\"Macro F1-Score: {results['macro_f1']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PER-CLASS METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"{'Emotion':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<12}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for i, emotion in enumerate(emotion_list):\n",
        "        print(f\"{emotion:<12} {results['precision'][i]:<12.4f} {results['recall'][i]:<12.4f} {results['f1'][i]:<12.4f} {results['support'][i]:<12}\")"
      ],
      "metadata": {
        "id": "CxVbp4J8Kec-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, emotion_list):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=emotion_list, yticklabels=emotion_list)\n",
        "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(results['confusion_matrix'], emotion_list)"
      ],
      "metadata": {
        "id": "UPDKGHx4Ksum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert Model to TensorRT**"
      ],
      "metadata": {
        "id": "U4A5DuUAkpwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(\n",
        "    \"model_merged_hf\",\n",
        "    tokenizer,\n",
        "    save_method = \"merged_16bit\",\n",
        ")"
      ],
      "metadata": {
        "id": "WcDKLY_-ZljF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trt_checkpoint\n",
        "\n",
        "!python -m tensorrt_llm.commands.convert_checkpoint \\\n",
        "    --model_dir ./model_merged_hf \\\n",
        "    --output_dir ./trt_checkpoint \\\n",
        "    --dtype float16 \\\n",
        "    --tp_size 1 \\\n",
        "    --workers 1"
      ],
      "metadata": {
        "id": "CxiVVFIKHulc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p trt_engine\n",
        "\n",
        "!trtllm-build \\\n",
        "    --checkpoint_dir ./trt_checkpoint \\\n",
        "    --output_dir ./trt_engine \\\n",
        "    --gemm_plugin float16 \\\n",
        "    --gpt_attention_plugin float16 \\\n",
        "    --max_batch_size 8 \\\n",
        "    --max_input_len 2048 \\\n",
        "    --max_output_len 1024"
      ],
      "metadata": {
        "id": "Iq70dUowH5Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runner = ModelRunner.from_dir(\"./trt_engine\")\n",
        "\n",
        "\n",
        "input_text = inference_prompt_style.format(\"I am feeling sad today.\")\n",
        "\n",
        "# Generate\n",
        "outputs = runner.generate(\n",
        "    [input_text],\n",
        "    max_new_tokens=500,\n",
        "    end_id=151643,\n",
        "    pad_id=151643\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./model_merged_hf\")\n",
        "\n",
        "output_ids = outputs[0][0].tolist() # Batch 0, Beam 0\n",
        "text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "tCfSefymIA2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}