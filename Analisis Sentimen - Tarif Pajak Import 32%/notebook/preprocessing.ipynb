{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6ThzZUp9Wyy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import re\n",
        "import nltk\n",
        "import shutil\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import tqdm.auto as tqdm\n",
        "import spacy\n",
        "import os\n",
        "import emoji\n",
        "import torch\n",
        "\n",
        "from transformers import pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import ngrams\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Data**"
      ],
      "metadata": {
        "id": "Zugb8S_tDp3i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-GePTPBDtE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filter Data**"
      ],
      "metadata": {
        "id": "k8FicsmSE1lm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qi4r5wPE4HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing**"
      ],
      "metadata": {
        "id": "xOe2ZWBtDPX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning_pipeline(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    def remove_emojis(input_text):\n",
        "        return emoji.replace_emoji(input_text, replace='')\n",
        "\n",
        "    step_1 = remove_emojis(text)\n",
        "    step_2 = replace_slang(step_1)\n",
        "    step_3 = re.sub(r'http\\S+', '', step_2)\n",
        "    step_4 = re.sub(r'\\B[@#]\\w+\\b', '', step_3)\n",
        "    step_6 = re.sub(r'\\d+', '', step_4)\n",
        "    step_7 = re.sub(r'\\s+', ' ', step_6)\n",
        "\n",
        "    words = step_7.split()\n",
        "    step_8 = ' '.join(sorted(set(words), key=words.index))\n",
        "\n",
        "    return step_8.strip().lower()"
      ],
      "metadata": {
        "id": "QOHm3LhgC9Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['full_text'] = df['full_text'].apply(data_cleaning_pipeline)\n",
        "df.dropna(subset=[\"full_text\"], inplace=True)\n",
        "df.drop_duplicates(subset=['full_text'], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "3H4o7-ZlDBTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"id\")\n",
        "nlp = stanza.Pipeline(\"id\")\n",
        "\n",
        "def lemmastanZa(teks):\n",
        "  doc = nlp(teks)\n",
        "  hasil = \" \".join([word.lemma for sentence in doc.sentences for word in sentence.words])\n",
        "  return hasil"
      ],
      "metadata": {
        "id": "SepHmILrDH47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Labeling Data**"
      ],
      "metadata": {
        "id": "Bz7TjnfCEXgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_name = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
        "nlp = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=pretrained_name,\n",
        "    tokenizer=pretrained_name\n",
        ")\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    if pd.isnull(text) or not isinstance(text, str):\n",
        "        return {\"label\": \"neutral\", \"score\": 0.0}\n",
        "    try:\n",
        "        result = nlp(text)[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {text}, Error: {e}\")\n",
        "        return {\"label\": \"neutral\", \"score\": 0.0}\n",
        "    return result\n",
        "\n",
        "data['full_text'] = data['full_text'].astype(str)\n",
        "data['sentiment_result'] = data['full_text'].apply(analyze_sentiment)\n",
        "\n",
        "data['sentiment'] = data['sentiment_result'].apply(lambda x: x['label'])\n",
        "data['sentiment_score'] = data['sentiment_result'].apply(lambda x: x['score'])"
      ],
      "metadata": {
        "id": "VPyMToclEZti"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}